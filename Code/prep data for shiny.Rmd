---
title: "Interactive Map with Emissions Data"
output: html_document
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(shiny)
library(leaflet)
library(dplyr)
library(sf)
library(scales) # For colorQuantile
```



```{r data}
PSE <- st_read("../Data/PSE_Gas_Tracts_2.shp")
PSE <- subset(PSE, Grouped_Fl=='TRUE')
PSE$Census_Tra <- as.character(PSE$Census_Tra)

# Renaming Columns for Clarity
PSE <- PSE %>% 
  rename(
    Grouped_Flag = Grouped_Fl, 
    `Gas Consumption` = Usage_MMBT, 
    `User Accounts` = Number_Acc, 
    `Gas Emissions` = Emissions_, 
    `Gas Usage Per Account` = USAGEPERCA, 
    `Emissions Per Account` = EMISSIONSP, 
    RSE_Quintile = RSE_Quinti, 
    SHAPE_Length = SHAPE_Leng
  )


PSE2023 <- PSE[PSE$CAL_YEAR==2023,]



PSE <- PSE %>%
  mutate(`Gas Consumption Percentile` = ntile(`Gas Consumption`, 100),
         `User Accounts Percentile` = ntile(`User Accounts`, 100),
         `Gas Emissions Percentile` = ntile(`Gas Emissions`, 100),
         `Gas Usage Per Account Percentile` = ntile(`Gas Usage Per Account`, 100),
         `Emissions Per Account Percentile` = ntile(`Emissions Per Account`, 100))


# Write a clean shp file to be used directly in Shiny
#st_write(PSE, '../Data/PSE.shp', delete_layer = TRUE)

head(PSE)
```

```{r filtered data}

#calculate reduced emissions per capita by proportions with total 39%
#sum total emissions and total for each sector
total_sum<-sum(PSE2023$`Emissions Per Account`)
PSE2023<-PSE2023 %>% group_by(Sector) %>%
 mutate(reduction_fact = sum(`Emissions Per Account`) / total_sum * (1-0.39))
#multiply data by proportions to reduce
#reduced_pse_2023$Emissions_reduced<-reduced_pse_2023$Emissions_ *reduced_pse_2023$reduction_fact
PSE2023<-PSE2023 %>% mutate(`epa_reduced` = `Emissions Per Account` * reduction_fact)
PSE2023<-PSE2023 %>% mutate(epa_reduced_total = `Emissions Per Account` * (1-0.39))

head(PSE2023)


quantiles <- quantile(PSE2023$`Emissions Per Account`, probs = seq(0.2, 0.8, by = 0.2), na.rm = TRUE)

# Create breaks with -Inf and Inf to capture everything below and above the quantiles
breaks <- c(-Inf, quantiles, Inf)

# Ensure we have the correct number of labels for the number of intervals created by the breaks
labels <- c("0-20%", "21-40%", "41-60%", "61-80%", "81-100%")
# Cut the Emissions_ data into bins based on these percentiles
PSE2023$Emissions_Percentile_Reduced <- cut(PSE2023$epa_reduced, 
                                           breaks = c(-Inf, quantiles, Inf), 
                                           include.lowest = TRUE, 
                                           labels = c("0-20%", "20-40%", "40-60%", "60-80%", "80-100%"))
PSE2023$Emissions_Percentile <- cut(PSE2023$`Emissions Per Account`, 
                                           breaks = c(-Inf, quantiles, Inf), 
                                           include.lowest = TRUE, 
                                           labels = c("0-20%", "20-40%", "40-60%", "60-80%", "80-100%"))

PSE2023 <- PSE2023 %>%
  mutate(`EPA` = ntile(`epa_reduced`, 100),
         `EPA_total` = ntile(`epa_reduced_total`, 100),
         `Emissions Per Account Percentile` = ntile(`Emissions Per Account`, 100)
         )


# Write a clean shp file to be used directly in Shiny

#st_write(PSE2023, '../Data/PSE2023.shp', delete_layer = TRUE)

#st_write(PSE2023, '../Data/PSE2023.shp', delete_layer = TRUE)


```



```{r}

library(sf)
library(dplyr)

# Reading the shapefile
Equity_RSE <- st_read("../Data/Race_and_Social_Equity_Composite_Index_for_2020_Census_Tract_Geographies.shp")

# Check for unique values before transformation
unique_compquin_values <- unique(Equity_RSE$COMPOSIT_1)
unique_healthquin_values <- unique(Equity_RSE$HEALTH_D_1)
unique_socioquin_values <- unique(Equity_RSE$SOCIOECO_2)
unique_racequin_values <- unique(Equity_RSE$RACE_ELL_1)


# Step 1: Creating a Subset of Relevant Columns and Renaming for Clarity
Equity_RSE <- Equity_RSE %>%
  select(
    ObjID = OBJECTID,
    GeoID = GEOID,
    ShpLen = SHAPE_Leng,
    ShpArea = SHAPE_Area,
    RaceQuin = RACE_ELL_1,
    SocioQuin = SOCIOECO_2,
    HealthQuin = HEALTH_D_1,
    CompQuin = COMPOSIT_1,
    geometry
  )

# Step 2: Checking for Null Values
null_values <- sapply(Equity_RSE, function(x) sum(is.na(x)))

# Step 3: Standardizing Quintile Labels
# Map the original text values to a numeric scale
quin_map <- setNames(1:5, unique_compquin_values[!is.na(unique_compquin_values)])
Equity_RSE$CompQuinNum <- unname(quin_map[Equity_RSE$CompQuin])

# Then, convert to factors with descriptive labels
Equity_RSE$CompQuinFactor <- factor(Equity_RSE$CompQuinNum,
                                    levels = 1:5,
                                    labels = c(
                                      "0th-20th percentile (Lowest Equity Priority)",
                                      "20th-40th percentile (Second Lowest Equity Priority)",
                                      "40th-60th percentile (Middle Equity Priority)",
                                      "60th-80th percentile (Second Highest Equity Priority)",
                                      "80th-100th percentile (Highest Equity Priority)"
                                    ))

# Assuming that you have a vector of unique values for each Quin like the following:
# unique_racequin_values, unique_socioquin_values, unique_healthquin_values

# Create a named vector that maps text values to numeric values for each Quin
racequin_map <- setNames(1:5, unique_racequin_values[!is.na(unique_racequin_values)])
socioquin_map <- setNames(1:5, unique_socioquin_values[!is.na(unique_socioquin_values)])
healthquin_map <- setNames(1:5, unique_healthquin_values[!is.na(unique_healthquin_values)])

# Map the original text values to a numeric scale for each Quin
Equity_RSE$RaceQuinNum <- unname(racequin_map[Equity_RSE$RaceQuin])
Equity_RSE$SocioQuinNum <- unname(socioquin_map[Equity_RSE$SocioQuin])
Equity_RSE$HealthQuinNum <- unname(healthquin_map[Equity_RSE$HealthQuin])

# Convert the numeric values to factors with descriptive labels for each Quin
Equity_RSE$RaceQuinFactor <- factor(Equity_RSE$RaceQuinNum,
                                    levels = 1:5,
                                    labels = c(
                                      "0th-20th percentile (Lowest Equity Priority)",
                                      "20th-40th percentile (Second Lowest Equity Priority)",
                                      "40th-60th percentile (Middle Equity Priority)",
                                      "60th-80th percentile (Second Highest Equity Priority)",
                                      "80th-100th percentile (Highest Equity Priority)"
                                    ))
Equity_RSE$SocioQuinFactor <- factor(Equity_RSE$SocioQuinNum,
                                     levels = 1:5,
                                     labels = c(
                                       "0th-20th percentile (Lowest Equity Priority)",
                                       "20th-40th percentile (Second Lowest Equity Priority)",
                                       "40th-60th percentile (Middle Equity Priority)",
                                       "60th-80th percentile (Second Highest Equity Priority)",
                                       "80th-100th percentile (Highest Equity Priority)"
                                     ))
Equity_RSE$HealthQuinFactor <- factor(Equity_RSE$HealthQuinNum,
                                      levels = 1:5,
                                      labels = c(
                                        "0th-20th percentile (Lowest Equity Priority)",
                                        "20th-40th percentile (Second Lowest Equity Priority)",
                                        "40th-60th percentile (Middle Equity Priority)",
                                        "60th-80th percentile (Second Highest Equity Priority)",
                                        "80th-100th percentile (Highest Equity Priority)"
                                      ))

# View the structure of the new factors to confirm they've been created correctly
str(Equity_RSE$RaceQuinFactor)
str(Equity_RSE$SocioQuinFactor)
str(Equity_RSE$HealthQuinFactor)


# Display the first few rows to verify the changes
head(Equity_RSE)

# Saving the processed data back to a shapefile
#st_write(Equity_RSE, '../Data/Equity_RSE.shp', delete_layer = TRUE)


```


```{r}
#unique_values <- unique()
#print(unique_values)

colnames(PSE)
colnames(Equity_RSE)

```




```{r dynamic sector graph for Emissions Per Account}

library(dplyr)
library(leaflet)
library(scales)  # For colorQuantile

# Assuming PSE is your dataset
# Filter the data for 'Sector' = 'Residential' and 'CAL_YEAR' = 2023
filtered_PSE <- PSE %>%
  filter(Sector == "Industrial", CAL_YEAR == 2023)

# Now use this filtered dataset in your leaflet map
leaflet(filtered_PSE) %>%
  addTiles() %>%
  addPolygons(
    fillColor = ~colorQuantile("YlOrRd", `Emissions Per Account`)(`Emissions Per Account`),
    weight = 2,
    opacity = 1,
    color = "white",
    dashArray = "3",
    fillOpacity = 0.7,
    highlightOptions = highlightOptions(
      weight = 5,
      color = "#666",
      dashArray = "",
      fillOpacity = 0.7,
      bringToFront = TRUE),
    label = ~paste0("Emissions: ", `Emissions Per Account`),
    labelOptions = labelOptions(
      style = list("font-weight" = "normal", padding = "3px 8px"),
      textsize = "15px",
      direction = "auto")
  ) %>%
  addLegend(
    pal = colorQuantile("YlOrRd", filtered_PSE$`Emissions Per Account`, n = 4),
    values = ~`Emissions Per Account`,
    opacity = 0.7,
    title = "Emissions Per Account",
    position = "bottomright")


```




```{r}

library(leaflet)
library(sf)

# Assuming 'Equity_RSE' is your cleaned and loaded spatial dataset

# Define a color palette for the factor levels of CompQuin using the provided hex colors
quin_colors <- colorFactor(
  palette = c("#2dc937", "#99c140", "#e7b416", "#db7b2b", "#cc3232"),
  domain = Equity_RSE$CompQuinFactor
)

# Create the Leaflet map
leaflet(Equity_RSE) %>%
  addProviderTiles(providers$CartoDB.Positron) %>%  # Adding a light-themed tile layer
  addPolygons(
    fillColor = ~quin_colors(CompQuinFactor),
    weight = 1,
    opacity = 1,
    color = "white",
    dashArray = "3",
    fillOpacity = 0.7,
    highlight = highlightOptions(
      weight = 3,
      color = "#666",
      dashArray = "",
      fillOpacity = 0.7,
      bringToFront = TRUE
    ),
    label = ~as.character(CompQuinFactor),
    labelOptions = labelOptions(
      style = list("font-weight" = "normal", padding = "3px 8px"),
      textsize = "13px",
      direction = "auto"
    )
  ) %>%
  addLegend(
    pal = quin_colors,
    values = ~CompQuinFactor,
    opacity = 0.7,
    title = "Equity Priority",
    position = "bottomright"
  )


```


```{r reduced emissions per capita}
quantiles <- quantile(PSE2023$`Emissions Per Account`, probs = seq(0.2, 0.8, by = 0.2), na.rm = TRUE)

# Create breaks with -Inf and Inf to capture everything below and above the quantiles
breaks <- c(-Inf, quantiles, Inf)

# Ensure we have the correct number of labels for the number of intervals created by the breaks
labels <- c("0-20%", "21-40%", "41-60%", "61-80%", "81-100%")
# Cut the Emissions_ data into bins based on these percentiles
PSE2023$Emissions_Percentile <- cut(PSE2023$epa_reduced, 
                                           breaks = c(-Inf, quantiles, Inf), 
                                           include.lowest = TRUE, 
                                           labels = c("0-20%", "20-40%", "40-60%", "60-80%", "80-100%"))

# Plot the map with emissions categorized by percentiles
ggplot() +
  geom_sf(data = seattle_base, fill = "white", color = "black", size = 0.1) +
  geom_sf(data = PSE2023, aes(fill = Emissions_Percentile), size = 0.1, alpha = 0.5) +
  scale_fill_manual(
    values = c("0-20%" = "#2dc937", "20-40%" = "#99c140", "40-60%" = "#e7b416", "60-80%" = "#db7b2b", "80-100%" = '#cc3232'),
    name = "Gas Emissions\n(Percentiles)"
  ) +
  labs(title = "Reduced Natural Gas Emissions Per Capita (MTCO2e)") +
  theme_minimal() +
  theme(legend.position = "bottom") +
  coord_sf(datum = NA)

head(PSE2023)
```



```{r}

quantiles <- quantile(PSE2023$`Emissions Per Account`, probs = seq(0.2, 0.8, by = 0.2), na.rm = TRUE)

# Create breaks with -Inf and Inf to capture everything below and above the quantiles
breaks <- c(-Inf, quantiles, Inf)

# Ensure we have the correct number of labels for the number of intervals created by the breaks
labels <- c("0-20%", "21-40%", "41-60%", "61-80%", "81-100%")

# Cut the Emissions_ data into bins based on these percentiles
PSE2023$Emissions_Percentile <- cut(PSE2023$`Emissions Per Account`, 
                                           breaks = c(-Inf, quantiles, Inf), 
                                           include.lowest = TRUE, 
                                           labels = c("0-20%", "20-40%", "40-60%", "60-80%", "80-100%"))

# Plot the map with emissions categorized by percentiles
ggplot() +
  geom_sf(data = seattle_base, fill = "white", color = "black", size = 0.1) +
  geom_sf(data = PSE2023, aes(fill = Emissions_Percentile), size = 0.1, alpha = 0.5) +
  scale_fill_manual(
    values = c("0-20%" = "#2dc937", "20-40%" = "#99c140", "40-60%" = "#e7b416", "60-80%" = "#db7b2b", "80-100%" = '#cc3232'),
    name = "Gas Emissions\n(Percentiles)"
  ) +
  labs(title = "Natural Gas Emissions Per Capita (MTCO2e)") +
  theme_minimal() +
  theme(legend.position = "bottom") +
  coord_sf(datum = NA)

```
```{r}

# Now use this filtered dataset in your leaflet map
leaflet(PSE2023) %>%
  addTiles() %>%
  addPolygons(
    fillColor = ~colorQuantile("YlOrRd", `Emissions Per Account`)(`Emissions Per Account`),
    weight = 2,
    opacity = 1,
    color = "white",
    dashArray = "3",
    fillOpacity = 0.7,
    highlightOptions = highlightOptions(
      weight = 5,
      color = "#666",
      dashArray = "",
      fillOpacity = 0.7,
      bringToFront = TRUE),
    label = ~paste0("Emissions: ", `Emissions Per Account`),
    labelOptions = labelOptions(
      style = list("font-weight" = "normal", padding = "3px 8px"),
      textsize = "15px",
      direction = "auto")
  ) %>%
  addLegend(
    pal = colorQuantile("YlOrRd", PSE2023$`Emissions Per Account`, n = 4),
    values = ~`Emissions Per Account`,
    opacity = 0.7,
    title = "Emissions Per Account",
    position = "bottomright")

```





```{r}
emissionsPalette <- colorFactor(palette = c("#2dc937", "#99c140", "#e7b416", "#db7b2b", "#cc3232"),
                                 domain = PSE2023$Emissions_Percentile)

# Create the leaflet map
leaflet(PSE2023) %>%
  #addTiles() %>%
  addProviderTiles(providers$CartoDB.Positron) %>%
  addPolygons(
    fillColor = ~emissionsPalette(Emissions_Percentile),
    weight = 2,
    opacity = 1,
    color = "white",
    dashArray = "3",
    fillOpacity = 0.7,
    highlightOptions = highlightOptions(
      weight = 5,
      color = "#666",
      dashArray = "",
      fillOpacity = 0.7,
      bringToFront = TRUE),
    label = ~paste0("Emissions: ", `Emissions Per Account`),
    labelOptions = labelOptions(
      style = list("font-weight" = "normal", padding = "3px 8px"),
      textsize = "15px",
      direction = "auto")
  ) %>%
  addLegend(
    pal = emissionsPalette,
    values = ~Emissions_Percentile,
    opacity = 0.7,
    title = "Emissions Per Account",
    position = "bottomright",
    labels = labels
  )
```
```{r}
# Define the breaks and labels for percentiles
#quantiles <- quantile(PSE2023$`Emissions Per Account`, probs = seq(0, 1, by = 0.2), na.rm = TRUE)
#breaks <- c(-Inf, quantiles, Inf)
#labels <- c("0-20%", "20-40%", "40-60%", "60-80%", "80-100%")

# Cut the data into bins based on percentiles
#PSE2023$Emissions_Percentile <- cut(PSE2023$`Emissions Per Account`, breaks = breaks, labels = labels, include.lowest = TRUE)

# Define the color palette for leaflet
emissionsReducedPalette <- colorFactor(palette = c("#2dc937", "#99c140", "#e7b416", "#db7b2b", "#cc3232"),
                                 domain = PSE2023$Emissions_Percentile_Reduced)

# Create the leaflet map
leaflet(PSE2023) %>%
  addProviderTiles(providers$CartoDB.Positron) %>%
  addPolygons(
    fillColor = ~emissionsReducedPalette(Emissions_Percentile_Reduced),
    weight = 2,
    opacity = 1,
    color = "white",
    dashArray = "3",
    fillOpacity = 0.7,
    highlightOptions = highlightOptions(
      weight = 5,
      color = "#666",
      dashArray = "",
      fillOpacity = 0.7,
      bringToFront = TRUE),
    label = ~paste0("Emissions: ", `Emissions Per Account`),
    labelOptions = labelOptions(
      style = list("font-weight" = "normal", padding = "3px 8px"),
      textsize = "15px",
      direction = "auto")
  ) %>%
  addLegend(
    pal = emissionsPalette,
    values = ~Emissions_Percentile_Reduced,
    opacity = 0.7,
    title = "Emissions Per Account",
    position = "bottomright",
    labels = labels
  )

```

















```{r mason}

#Masons data and cleaning
data2022 <- read.csv("../Data/Performance_Ranges_by_Building_Type_2022.csv")
data2021 <- read.csv("../Data/Performance_Ranges_by_Building_Type_2021.csv")
data2020 <- read.csv("../Data/Performance_Ranges_by_Building_Type_2020.csv")
data2019 <- read.csv("../Data/Performance_Ranges_By_Building_Type_2019.csv")
data2018 <- read.csv("../Data/Performance_Ranges_By_Building_Type_2018.csv")
data2017 <- read.csv("../Data/Performance_Ranges_by_Building_Type_2017.csv")
data2016 <- read.csv("../Data/Performance_Ranges_By_Building_Type_2016.csv")

data2017 <- select(data2017, -c(Low.Outlier.Cutoff, High.Outlier.Cutoff))
data2022 <- na.omit(data2022)
data2021 <- na.omit(data2021)
data2020 <- na.omit(data2020)
data2019 <- na.omit(data2019)
data2018 <- na.omit(data2018)
data2017 <- na.omit(data2017)
data2016 <- na.omit(data2016)

#We are renaming all the columns names for all the years so they are all uniform so we can join them later. The order does not matter right now, we are going with the order of how they are in their respective files.

colnames(data2016) <- c("BuildingType", "Percentile_25th_EUI", "Median_EUI", "Percentile_75th_EUI", "Median_EUI_WN", "Median_Source_EUI", "Median_ES_Score", "Number_of_Buildings", "Total_GFA", "Median_GFA", "Median_Year_Built", "Percent_Electricity", "Percent_Gas", "Percent_Steam", "Percent_Other_Fuel")

colnames(data2017) <- c("BuildingType", "Percentile_25th_EUI", "Median_EUI", "Percentile_75th_EUI", "Median_EUI_WN", "Median_Source_EUI", "Median_ES_Score", "Number_of_Buildings", "Number_of_Buildings_with_ES_Score", "Total_GFA", "Median_GFA", "Median_Year_Built", "Percent_Electricity", "Percent_Gas", "Percent_Steam", "Percent_Other_Fuel")

colnames(data2018) <- c("BuildingType", "Number_of_Buildings", "Percentile_25th_EUI", "Median_EUI", "Percentile_75th_EUI", "Average_Site_EUI", "Average_Site_EUI_WN", "Median_EUI", "Median_ES_Score", "Total_GFA", "Median_GFA", "Median_Year_Built", "Not applies")

colnames(data2019) <- c("BuildingType", "Number_of_Buildings", "Percentile_25th_EUI", "Median_EUI", "Percentile_75th_EUI", "Median_EUI_WN", "Average_Site_EUI", "Average_Site_EUI_WN", "Median_Source_EUI", "Median_ES_Score", "Average_ES_Score", "Total_GFA", "Median_GFA", "Median_Year_Built", "Average_GHGSF", "MedianGHGSF")

colnames(data2020) <- c("BuildingType", "Number_of_Buildings", "Percentile_25th_EUI", "Median_EUI", "Percentile_75th_EUI", "Median_EUI_WN", "Average_Site_EUI", "Average_Site_EUI_WN", "Median_Source_EUI", "Median_ES_Score", "Average_ES_Score", "Total_GFA", "Median_GFA", "Median_Year_Built", "Average_GHGSF", "MedianGHGSF")

colnames(data2021) <- c("BuildingType", "Number_of_Buildings", "Percentile_25th_EUI", "Median_EUI", "Percentile_75th_EUI", "Median_EUI_WN", "Average_Site_EUI", "Average_Site_EUI_WN", "Median_Source_EUI", "Median_ES_Score", "Average_ES_Score", "Total_GFA", "Median_GFA", "Median_Year_Built", "Average_GHGSF", "MedianGHGSF")

colnames(data2022) <- c("BuildingType", "Number_of_Buildings", "Percentile_25th_EUI", "Median_EUI", "Percentile_75th_EUI", "Median_EUI_WN", "Average_Site_EUI", "Average_Site_EUI_WN", "Median_Source_EUI", "Median_ES_Score", "Average_ES_Score", "Total_GFA", "Median_GFA", "Median_Year_Built", "Average_GHGSF", "MedianGHGSF")

#we are doign 3 checks to see if every column in every year is in 2022, 2016 and 2018 respecitvely as I was having issues with incompatible dataset before
data2016 <- data2016[, colnames(data2016) %in% colnames(data2022)]
data2017 <- data2017[, colnames(data2017) %in% colnames(data2022)]
data2018 <- data2018[, colnames(data2018) %in% colnames(data2022)]
data2019 <- data2019[, colnames(data2019) %in% colnames(data2022)]
data2020 <- data2020[, colnames(data2020) %in% colnames(data2022)]
data2021 <- data2021[, colnames(data2021) %in% colnames(data2022)]

data2016 <- data2016[, colnames(data2016) %in% colnames(data2016)]
data2017 <- data2017[, colnames(data2017) %in% colnames(data2016)]
data2018 <- data2018[, colnames(data2018) %in% colnames(data2016)]
data2019 <- data2019[, colnames(data2019) %in% colnames(data2016)]
data2020 <- data2020[, colnames(data2020) %in% colnames(data2016)]
data2021 <- data2021[, colnames(data2021) %in% colnames(data2016)]
data2022 <- data2022[, colnames(data2022) %in% colnames(data2016)]

data2016 <- data2016[, colnames(data2016) %in% colnames(data2018)]
data2017 <- data2017[, colnames(data2017) %in% colnames(data2018)]
data2018 <- data2018[, colnames(data2018) %in% colnames(data2018)]
data2019 <- data2019[, colnames(data2019) %in% colnames(data2018)]
data2020 <- data2020[, colnames(data2020) %in% colnames(data2018)]
data2021 <- data2021[, colnames(data2021) %in% colnames(data2018)]
data2022 <- data2022[, colnames(data2022) %in% colnames(data2018)]

#we are adding a year column to every dataset 
library(dplyr)
data2022 <- mutate(data2022, Year = 2022)
data2021 <- mutate(data2021, Year = 2021)
data2020 <- mutate(data2020, Year = 2020)
data2019 <- mutate(data2019, Year = 2019)
data2018 <- mutate(data2018, Year = 2018)
data2017 <- mutate(data2017, Year = 2017)
data2016 <- mutate(data2016, Year = 2016)

#we are now going to combine all our datasets
combined_data <- bind_rows(
  mutate(data2016, Year = 2016),
  mutate(data2017, Year = 2017),
  mutate(data2018, Year = 2018),
  mutate(data2019, Year = 2019),
  mutate(data2020, Year = 2020),
  mutate(data2021, Year = 2021),
  mutate(data2022, Year = 2022)
)
combined_data<- combined_data[combined_data$BuildingType != "Citywide", ]

#Masons work starts here 
  #looks like we lost data somewhere here but we will figure that out later
  commercial_data <- combined_data %>% filter(grepl("Grocery|Hospital|K-12|Office|Medical|Mixed|Other|Retail|Worship", BuildingType))
  
  industrial_data <- combined_data %>% filter(grepl("Distribution|Warehouse", BuildingType))
  
  residential_data <- combined_data %>% filter(grepl("High-rise|Low-rise|Mid-rise|Residence|Senior|Multifamily", BuildingType))
  
  industrial_data_year <- industrial_data %>% 
    group_by(Year) %>%
    filter(Year != 2020) %>%
    summarize(Average_Median_EUI = mean(Median_EUI))
  
  residential_data_year <- residential_data %>% 
    group_by(Year) %>%
    filter(Year != 2020) %>%
    summarize(Average_Median_EUI = mean(Median_EUI))
  
  
  commercial_data_year <- commercial_data %>% 
    group_by(Year) %>%
    filter(Year != 2020) %>%
    summarize(Average_Median_EUI = mean(Median_EUI))
  
  general_data_year <- combined_data %>%
    group_by(Year) %>% 
    summarize(Average_Median_EUI = mean(Median_EUI)) %>%
    filter(Year != 2020)
  
  
  commercial_lm <-lm(Average_Median_EUI ~ Year, data = commercial_data_year)
  
  industrial_lm <- lm(Average_Median_EUI ~ Year, data = industrial_data_year)
  
  residential_lm <- lm(Average_Median_EUI ~ Year, data = residential_data_year)
  
  general_lm <- lm(Average_Median_EUI ~ Year, data = general_data_year)
  
  
    

```








=======
>>>>>>> workspace/Bogi

# Now use this filtered dataset in your leaflet map
leaflet(PSE2023) %>%
  addTiles() %>%
  addPolygons(
    fillColor = ~colorQuantile("YlOrRd", `Emissions Per Account`)(`Emissions Per Account`),
    weight = 2,
    opacity = 1,
    color = "white",
    dashArray = "3",
    fillOpacity = 0.7,
    highlightOptions = highlightOptions(
      weight = 5,
      color = "#666",
      dashArray = "",
      fillOpacity = 0.7,
      bringToFront = TRUE),
    label = ~paste0("Emissions: ", `Emissions Per Account`),
    labelOptions = labelOptions(
      style = list("font-weight" = "normal", padding = "3px 8px"),
      textsize = "15px",
      direction = "auto")
  ) %>%
  addLegend(
    pal = colorQuantile("YlOrRd", PSE2023$`Emissions Per Account`, n = 4),
    values = ~`Emissions Per Account`,
    opacity = 0.7,
    title = "Emissions Per Account",
    position = "bottomright")

```





```{r}
emissionsPalette <- colorFactor(palette = c("#2dc937", "#99c140", "#e7b416", "#db7b2b", "#cc3232"),
                                 domain = PSE2023$Emissions_Percentile)

# Create the leaflet map
leaflet(PSE2023) %>%
  #addTiles() %>%
  addProviderTiles(providers$CartoDB.Positron) %>%
  addPolygons(
    fillColor = ~emissionsPalette(Emissions_Percentile),
    weight = 2,
    opacity = 1,
    color = "white",
    dashArray = "3",
    fillOpacity = 0.7,
    highlightOptions = highlightOptions(
      weight = 5,
      color = "#666",
      dashArray = "",
      fillOpacity = 0.7,
      bringToFront = TRUE),
    label = ~paste0("Emissions: ", `Emissions Per Account`),
    labelOptions = labelOptions(
      style = list("font-weight" = "normal", padding = "3px 8px"),
      textsize = "15px",
      direction = "auto")
  ) %>%
  addLegend(
    pal = emissionsPalette,
    values = ~Emissions_Percentile,
    opacity = 0.7,
    title = "Emissions Per Account",
    position = "bottomright",
    labels = labels
  )
```
```{r}
# Define the breaks and labels for percentiles
#quantiles <- quantile(PSE2023$`Emissions Per Account`, probs = seq(0, 1, by = 0.2), na.rm = TRUE)
#breaks <- c(-Inf, quantiles, Inf)
#labels <- c("0-20%", "20-40%", "40-60%", "60-80%", "80-100%")

# Cut the data into bins based on percentiles
#PSE2023$Emissions_Percentile <- cut(PSE2023$`Emissions Per Account`, breaks = breaks, labels = labels, include.lowest = TRUE)

# Define the color palette for leaflet
emissionsReducedPalette <- colorFactor(palette = c("#2dc937", "#99c140", "#e7b416", "#db7b2b", "#cc3232"),
                                 domain = PSE2023$Emissions_Percentile_Reduced)

# Create the leaflet map
leaflet(PSE2023) %>%
  addProviderTiles(providers$CartoDB.Positron) %>%
  addPolygons(
    fillColor = ~emissionsReducedPalette(Emissions_Percentile_Reduced),
    weight = 2,
    opacity = 1,
    color = "white",
    dashArray = "3",
    fillOpacity = 0.7,
    highlightOptions = highlightOptions(
      weight = 5,
      color = "#666",
      dashArray = "",
      fillOpacity = 0.7,
      bringToFront = TRUE),
    label = ~paste0("Emissions: ", `Emissions Per Account`),
    labelOptions = labelOptions(
      style = list("font-weight" = "normal", padding = "3px 8px"),
      textsize = "15px",
      direction = "auto")
  ) %>%
  addLegend(
    pal = emissionsPalette,
    values = ~Emissions_Percentile_Reduced,
    opacity = 0.7,
    title = "Emissions Per Account",
    position = "bottomright",
    labels = labels
  )

```

















```{r mason}

#Masons data and cleaning
data2022 <- read.csv("../Data/Performance_Ranges_by_Building_Type_2022.csv")
data2021 <- read.csv("../Data/Performance_Ranges_by_Building_Type_2021.csv")
data2020 <- read.csv("../Data/Performance_Ranges_by_Building_Type_2020.csv")
data2019 <- read.csv("../Data/Performance_Ranges_By_Building_Type_2019.csv")
data2018 <- read.csv("../Data/Performance_Ranges_By_Building_Type_2018.csv")
data2017 <- read.csv("../Data/Performance_Ranges_by_Building_Type_2017.csv")
data2016 <- read.csv("../Data/Performance_Ranges_By_Building_Type_2016.csv")

data2017 <- select(data2017, -c(Low.Outlier.Cutoff, High.Outlier.Cutoff))
data2022 <- na.omit(data2022)
data2021 <- na.omit(data2021)
data2020 <- na.omit(data2020)
data2019 <- na.omit(data2019)
data2018 <- na.omit(data2018)
data2017 <- na.omit(data2017)
data2016 <- na.omit(data2016)

#We are renaming all the columns names for all the years so they are all uniform so we can join them later. The order does not matter right now, we are going with the order of how they are in their respective files.

colnames(data2016) <- c("BuildingType", "Percentile_25th_EUI", "Median_EUI", "Percentile_75th_EUI", "Median_EUI_WN", "Median_Source_EUI", "Median_ES_Score", "Number_of_Buildings", "Total_GFA", "Median_GFA", "Median_Year_Built", "Percent_Electricity", "Percent_Gas", "Percent_Steam", "Percent_Other_Fuel")

colnames(data2017) <- c("BuildingType", "Percentile_25th_EUI", "Median_EUI", "Percentile_75th_EUI", "Median_EUI_WN", "Median_Source_EUI", "Median_ES_Score", "Number_of_Buildings", "Number_of_Buildings_with_ES_Score", "Total_GFA", "Median_GFA", "Median_Year_Built", "Percent_Electricity", "Percent_Gas", "Percent_Steam", "Percent_Other_Fuel")

colnames(data2018) <- c("BuildingType", "Number_of_Buildings", "Percentile_25th_EUI", "Median_EUI", "Percentile_75th_EUI", "Average_Site_EUI", "Average_Site_EUI_WN", "Median_EUI", "Median_ES_Score", "Total_GFA", "Median_GFA", "Median_Year_Built", "Not applies")

colnames(data2019) <- c("BuildingType", "Number_of_Buildings", "Percentile_25th_EUI", "Median_EUI", "Percentile_75th_EUI", "Median_EUI_WN", "Average_Site_EUI", "Average_Site_EUI_WN", "Median_Source_EUI", "Median_ES_Score", "Average_ES_Score", "Total_GFA", "Median_GFA", "Median_Year_Built", "Average_GHGSF", "MedianGHGSF")

colnames(data2020) <- c("BuildingType", "Number_of_Buildings", "Percentile_25th_EUI", "Median_EUI", "Percentile_75th_EUI", "Median_EUI_WN", "Average_Site_EUI", "Average_Site_EUI_WN", "Median_Source_EUI", "Median_ES_Score", "Average_ES_Score", "Total_GFA", "Median_GFA", "Median_Year_Built", "Average_GHGSF", "MedianGHGSF")

colnames(data2021) <- c("BuildingType", "Number_of_Buildings", "Percentile_25th_EUI", "Median_EUI", "Percentile_75th_EUI", "Median_EUI_WN", "Average_Site_EUI", "Average_Site_EUI_WN", "Median_Source_EUI", "Median_ES_Score", "Average_ES_Score", "Total_GFA", "Median_GFA", "Median_Year_Built", "Average_GHGSF", "MedianGHGSF")

colnames(data2022) <- c("BuildingType", "Number_of_Buildings", "Percentile_25th_EUI", "Median_EUI", "Percentile_75th_EUI", "Median_EUI_WN", "Average_Site_EUI", "Average_Site_EUI_WN", "Median_Source_EUI", "Median_ES_Score", "Average_ES_Score", "Total_GFA", "Median_GFA", "Median_Year_Built", "Average_GHGSF", "MedianGHGSF")

#we are doign 3 checks to see if every column in every year is in 2022, 2016 and 2018 respecitvely as I was having issues with incompatible dataset before
data2016 <- data2016[, colnames(data2016) %in% colnames(data2022)]
data2017 <- data2017[, colnames(data2017) %in% colnames(data2022)]
data2018 <- data2018[, colnames(data2018) %in% colnames(data2022)]
data2019 <- data2019[, colnames(data2019) %in% colnames(data2022)]
data2020 <- data2020[, colnames(data2020) %in% colnames(data2022)]
data2021 <- data2021[, colnames(data2021) %in% colnames(data2022)]

data2016 <- data2016[, colnames(data2016) %in% colnames(data2016)]
data2017 <- data2017[, colnames(data2017) %in% colnames(data2016)]
data2018 <- data2018[, colnames(data2018) %in% colnames(data2016)]
data2019 <- data2019[, colnames(data2019) %in% colnames(data2016)]
data2020 <- data2020[, colnames(data2020) %in% colnames(data2016)]
data2021 <- data2021[, colnames(data2021) %in% colnames(data2016)]
data2022 <- data2022[, colnames(data2022) %in% colnames(data2016)]

data2016 <- data2016[, colnames(data2016) %in% colnames(data2018)]
data2017 <- data2017[, colnames(data2017) %in% colnames(data2018)]
data2018 <- data2018[, colnames(data2018) %in% colnames(data2018)]
data2019 <- data2019[, colnames(data2019) %in% colnames(data2018)]
data2020 <- data2020[, colnames(data2020) %in% colnames(data2018)]
data2021 <- data2021[, colnames(data2021) %in% colnames(data2018)]
data2022 <- data2022[, colnames(data2022) %in% colnames(data2018)]

#we are adding a year column to every dataset 
library(dplyr)
data2022 <- mutate(data2022, Year = 2022)
data2021 <- mutate(data2021, Year = 2021)
data2020 <- mutate(data2020, Year = 2020)
data2019 <- mutate(data2019, Year = 2019)
data2018 <- mutate(data2018, Year = 2018)
data2017 <- mutate(data2017, Year = 2017)
data2016 <- mutate(data2016, Year = 2016)

#we are now going to combine all our datasets
combined_data <- bind_rows(
  mutate(data2016, Year = 2016),
  mutate(data2017, Year = 2017),
  mutate(data2018, Year = 2018),
  mutate(data2019, Year = 2019),
  mutate(data2020, Year = 2020),
  mutate(data2021, Year = 2021),
  mutate(data2022, Year = 2022)
)
combined_data<- combined_data[combined_data$BuildingType != "Citywide", ]

#Masons work starts here 
  #looks like we lost data somewhere here but we will figure that out later
  commercial_data <- combined_data %>% filter(grepl("Grocery|Hospital|K-12|Office|Medical|Mixed|Other|Retail|Worship", BuildingType))
  
  industrial_data <- combined_data %>% filter(grepl("Distribution|Warehouse", BuildingType))
  
  residential_data <- combined_data %>% filter(grepl("High-rise|Low-rise|Mid-rise|Residence|Senior|Multifamily", BuildingType))
  
  industrial_data_year <- industrial_data %>% 
    group_by(Year) %>%
    filter(Year != 2020) %>%
    summarize(Average_Median_EUI = mean(Median_EUI))
  
  residential_data_year <- residential_data %>% 
    group_by(Year) %>%
    filter(Year != 2020) %>%
    summarize(Average_Median_EUI = mean(Median_EUI))
  
  
  commercial_data_year <- commercial_data %>% 
    group_by(Year) %>%
    filter(Year != 2020) %>%
    summarize(Average_Median_EUI = mean(Median_EUI))
  
  general_data_year <- combined_data %>%
    group_by(Year) %>% 
    summarize(Average_Median_EUI = mean(Median_EUI)) %>%
    filter(Year != 2020)
  
  
  commercial_lm <-lm(Average_Median_EUI ~ Year, data = commercial_data_year)
  
  industrial_lm <- lm(Average_Median_EUI ~ Year, data = industrial_data_year)
  
  residential_lm <- lm(Average_Median_EUI ~ Year, data = residential_data_year)
  
  general_lm <- lm(Average_Median_EUI ~ Year, data = general_data_year)
  
  
    

```


